{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35a200f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-11 00:10:11.419190: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers.merge import concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, BatchNormalization, Dense, Conv2D, MaxPool2D , Flatten, Dropout, GlobalAveragePooling2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.applications import EfficientNetB3\n",
    "from tensorflow.keras.applications.densenet import preprocess_input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a09baf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from PIL import Image\n",
    "sys.modules['Image'] = Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7659c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-11 00:10:12.508707: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-01-11 00:10:12.509229: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-01-11 00:10:12.544950: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-11 00:10:12.545291: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.91GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-01-11 00:10:12.545304: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-01-11 00:10:12.546879: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2022-01-11 00:10:12.546911: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-01-11 00:10:12.547560: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-01-11 00:10:12.547705: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-01-11 00:10:12.549526: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-01-11 00:10:12.549930: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2022-01-11 00:10:12.550038: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-01-11 00:10:12.550119: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-11 00:10:12.550490: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-11 00:10:12.550886: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "006c8e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"GPUs: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "889cf590",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_metadata.csv')\n",
    "test = pd.read_csv('test_metadata.csv')\n",
    "#submission = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "train_dir = 'train/'\n",
    "test_dir = 'test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc0ff3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = []\n",
    "train_data = []\n",
    "for i in range(train.shape[0]):\n",
    "    train_data.append(train_dir + train['image_name'].iloc[i] + '.jpg')\n",
    "    label.append(train['diagnosis'].iloc[i])\n",
    "    \n",
    "test_data = []\n",
    "for i in range(test.shape[0]):\n",
    "    test_data.append(test_dir + test['image'].iloc[i] + '.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6378e83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiIndex([('atypical melanocytic proliferation',),\n",
      "            (               'cafe-au-lait macule',),\n",
      "            (                       'lentigo NOS',),\n",
      "            (               'lichenoid keratosis',),\n",
      "            (                          'melanoma',),\n",
      "            (                             'nevus',),\n",
      "            (              'seborrheic keratosis',),\n",
      "            (                     'solar lentigo',),\n",
      "            (                           'unknown',)],\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "label_df = pd.DataFrame(label, columns = ['diagnosis'])\n",
    "one_hot_encoder.fit(label_df)\n",
    "\n",
    "label_df_encoded = one_hot_encoder.transform(label_df)\n",
    "label_df_encoded = pd.DataFrame(data=label_df_encoded, columns=one_hot_encoder.categories_)\n",
    "print(label_df_encoded.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9b51463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([                               'images',\n",
      "       ('atypical melanocytic proliferation',),\n",
      "                      ('cafe-au-lait macule',),\n",
      "                              ('lentigo NOS',),\n",
      "                      ('lichenoid keratosis',),\n",
      "                                 ('melanoma',),\n",
      "                                    ('nevus',),\n",
      "                     ('seborrheic keratosis',),\n",
      "                            ('solar lentigo',),\n",
      "                                  ('unknown',)],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.DataFrame(train_data)\n",
    "df_train.columns = ['images']\n",
    "df_train = pd.concat([df_train, label_df_encoded], axis = 1)\n",
    "print(df_train.columns)\n",
    "df_test = pd.DataFrame(test_data)\n",
    "df_test.columns = ['images']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "520503ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_train.iloc[:, 0], df_train.iloc[:,1::], test_size = 0.3, random_state = 42)\n",
    "\n",
    "train = pd.DataFrame(X_train)\n",
    "train.columns = ['images']\n",
    "train = pd.concat([train, y_train], axis = 1)\n",
    "\n",
    "test = pd.DataFrame(X_test)\n",
    "test.columns = ['images']\n",
    "test = pd.concat([test, y_test], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a15a7a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23188 validated image filenames.\n",
      "Found 9938 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,rotation_range=50,\n",
    "                                   zoom_range = 0.3,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range = 0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode = 'nearest')\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train,\n",
    "    x_col=train.columns[0],\n",
    "    y_col=train.columns[1:],\n",
    "    target_size=(300, 300),\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    class_mode='raw')\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    test,\n",
    "    x_col=test.columns[0],\n",
    "    y_col=test.columns[1:],\n",
    "    target_size=(300, 300),\n",
    "    shuffle=False,\n",
    "    batch_size=8,\n",
    "    class_mode='raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8810b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-11 00:10:13.127837: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-11 00:10:13.128251: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-01-11 00:10:13.128373: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-11 00:10:13.128758: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.91GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-01-11 00:10:13.128779: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-01-11 00:10:13.128808: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2022-01-11 00:10:13.128820: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-01-11 00:10:13.128830: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-01-11 00:10:13.128839: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-01-11 00:10:13.128850: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-01-11 00:10:13.128859: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2022-01-11 00:10:13.128869: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-01-11 00:10:13.128924: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-11 00:10:13.129279: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-11 00:10:13.129671: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-01-11 00:10:13.129693: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-01-11 00:10:13.481812: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-01-11 00:10:13.481829: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2022-01-11 00:10:13.481834: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2022-01-11 00:10:13.481997: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-11 00:10:13.482386: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-11 00:10:13.482725: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-11 00:10:13.483039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10148 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "        EfficientNetB3(\n",
    "            input_shape=(300,300,3),\n",
    "            weights='imagenet',\n",
    "            include_top=False\n",
    "        ),\n",
    "        GlobalAveragePooling2D(),\n",
    "        Dense(1024, activation = 'relu'), \n",
    "        Dropout(0.3), \n",
    "        Dense(512, activation= 'relu'), \n",
    "        Dropout(0.2), \n",
    "        Dense(256, activation='relu'), \n",
    "        Dropout(0.2), \n",
    "        Dense(128, activation='relu'), \n",
    "        Dropout(0.1), \n",
    "        Dense(9, activation='softmax')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "793a1624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "efficientnetb3 (Functional)  (None, 10, 10, 1536)      10783535  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              1573888   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 9)                 1161      \n",
      "=================================================================\n",
      "Total params: 13,047,608\n",
      "Trainable params: 12,960,305\n",
      "Non-trainable params: 87,303\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "opt = Adam(lr=0.0001)\n",
    "\n",
    "model.compile(optimizer= opt,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a407e7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deeplab/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      "2022-01-11 00:10:16.178527: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-01-11 00:10:16.198209: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 4200000000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-11 00:10:23.717994: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2022-01-11 00:10:23.876486: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-01-11 00:10:24.028974: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181/181 [==============================] - 107s 540ms/step - loss: 0.9199 - accuracy: 0.7724 - val_loss: 0.8007 - val_accuracy: 0.8068\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.80682, saving model to efficientB3_1.h5\n",
      "Epoch 2/100\n",
      "181/181 [==============================] - 95s 522ms/step - loss: 0.3831 - accuracy: 0.9199 - val_loss: 0.7866 - val_accuracy: 0.8052\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.80682\n",
      "Epoch 3/100\n",
      "181/181 [==============================] - 95s 525ms/step - loss: 0.3991 - accuracy: 0.9200 - val_loss: 0.6706 - val_accuracy: 0.8068\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.80682\n",
      "Epoch 4/100\n",
      "181/181 [==============================] - 95s 523ms/step - loss: 0.2448 - accuracy: 0.9414 - val_loss: 0.7275 - val_accuracy: 0.8003\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.80682\n",
      "Epoch 5/100\n",
      "181/181 [==============================] - 92s 505ms/step - loss: 0.2947 - accuracy: 0.9285 - val_loss: 561.5774 - val_accuracy: 0.7906\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.80682\n",
      "Epoch 6/100\n",
      "181/181 [==============================] - 90s 497ms/step - loss: 0.3424 - accuracy: 0.9269 - val_loss: 0.6430 - val_accuracy: 0.7825\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.80682\n",
      "Epoch 7/100\n",
      "181/181 [==============================] - 86s 477ms/step - loss: 0.2655 - accuracy: 0.9341 - val_loss: 21865.5547 - val_accuracy: 0.8068\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.80682\n",
      "Epoch 8/100\n",
      "181/181 [==============================] - 88s 484ms/step - loss: 0.2640 - accuracy: 0.9369 - val_loss: 0.4306 - val_accuracy: 0.8782\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.80682 to 0.87825, saving model to efficientB3_1.h5\n",
      "Epoch 9/100\n",
      "181/181 [==============================] - 85s 470ms/step - loss: 0.3256 - accuracy: 0.9193 - val_loss: 0.7017 - val_accuracy: 0.7484\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.87825\n",
      "Epoch 10/100\n",
      "181/181 [==============================] - 85s 469ms/step - loss: 0.2059 - accuracy: 0.9516 - val_loss: 0.7223 - val_accuracy: 0.6769\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.87825\n",
      "Epoch 11/100\n",
      "181/181 [==============================] - 87s 482ms/step - loss: 0.2528 - accuracy: 0.9336 - val_loss: 120044.3516 - val_accuracy: 0.8052\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.87825\n",
      "Epoch 12/100\n",
      "181/181 [==============================] - 89s 490ms/step - loss: 0.2170 - accuracy: 0.9491 - val_loss: 158542.3281 - val_accuracy: 0.8068\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.87825\n",
      "Epoch 13/100\n",
      "181/181 [==============================] - 85s 469ms/step - loss: 0.2499 - accuracy: 0.9384 - val_loss: 1.1205 - val_accuracy: 0.8068\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.87825\n",
      "Epoch 14/100\n",
      "181/181 [==============================] - 86s 475ms/step - loss: 0.2316 - accuracy: 0.9490 - val_loss: 29.1741 - val_accuracy: 0.8166\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.87825\n",
      "Epoch 15/100\n",
      "181/181 [==============================] - 86s 477ms/step - loss: 0.2861 - accuracy: 0.9283 - val_loss: 3123.5378 - val_accuracy: 0.5260\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.87825\n",
      "Epoch 16/100\n",
      "181/181 [==============================] - 84s 465ms/step - loss: 0.2246 - accuracy: 0.9438 - val_loss: 0.6684 - val_accuracy: 0.8068\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.87825\n",
      "Epoch 17/100\n",
      "181/181 [==============================] - 87s 480ms/step - loss: 0.2241 - accuracy: 0.9422 - val_loss: 0.5151 - val_accuracy: 0.8344\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.87825\n",
      "Epoch 18/100\n",
      "181/181 [==============================] - 87s 479ms/step - loss: 0.2335 - accuracy: 0.9447 - val_loss: 0.5988 - val_accuracy: 0.8133\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.87825\n",
      "Epoch 19/100\n",
      "181/181 [==============================] - 85s 471ms/step - loss: 0.2556 - accuracy: 0.9345 - val_loss: 1.0654 - val_accuracy: 0.8068\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.87825\n",
      "Epoch 20/100\n",
      "181/181 [==============================] - 86s 473ms/step - loss: 0.2008 - accuracy: 0.9510 - val_loss: 16140.6348 - val_accuracy: 0.8068\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.87825\n",
      "Epoch 21/100\n",
      "181/181 [==============================] - 85s 471ms/step - loss: 0.2260 - accuracy: 0.9396 - val_loss: 0.8726 - val_accuracy: 0.8068\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.87825\n",
      "Epoch 22/100\n",
      "181/181 [==============================] - 88s 483ms/step - loss: 0.2661 - accuracy: 0.9359 - val_loss: 0.8288 - val_accuracy: 0.8068\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.87825\n",
      "Epoch 23/100\n",
      "181/181 [==============================] - 87s 481ms/step - loss: 0.2666 - accuracy: 0.9283 - val_loss: 164.6811 - val_accuracy: 0.8036\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.87825\n",
      "Epoch 24/100\n",
      "181/181 [==============================] - 85s 470ms/step - loss: 0.2292 - accuracy: 0.9407 - val_loss: 37167.2188 - val_accuracy: 0.8068\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.87825\n",
      "Epoch 25/100\n",
      "181/181 [==============================] - 88s 485ms/step - loss: 0.2293 - accuracy: 0.9454 - val_loss: 77056.6953 - val_accuracy: 0.8068\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.87825\n",
      "Epoch 26/100\n",
      "181/181 [==============================] - 85s 470ms/step - loss: 0.2169 - accuracy: 0.9466 - val_loss: 0.6288 - val_accuracy: 0.8084\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.87825\n",
      "Epoch 27/100\n",
      "181/181 [==============================] - 87s 479ms/step - loss: 0.2014 - accuracy: 0.9496 - val_loss: 0.7845 - val_accuracy: 0.7370\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.87825\n",
      "Epoch 28/100\n",
      "181/181 [==============================] - 89s 488ms/step - loss: 0.1840 - accuracy: 0.9521 - val_loss: 0.4867 - val_accuracy: 0.8555\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.87825\n",
      "Epoch 29/100\n",
      "181/181 [==============================] - 86s 475ms/step - loss: 0.2496 - accuracy: 0.9393 - val_loss: 0.8590 - val_accuracy: 0.8068\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.87825\n",
      "Epoch 30/100\n",
      "181/181 [==============================] - 88s 488ms/step - loss: 0.3058 - accuracy: 0.9258 - val_loss: 0.7125 - val_accuracy: 0.8068\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.87825\n",
      "Epoch 31/100\n",
      "181/181 [==============================] - 90s 497ms/step - loss: 0.2302 - accuracy: 0.9446 - val_loss: 1.7867 - val_accuracy: 0.7890\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.87825\n",
      "Epoch 32/100\n",
      "181/181 [==============================] - 89s 491ms/step - loss: 0.1840 - accuracy: 0.9472 - val_loss: 0.6243 - val_accuracy: 0.7938\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.87825\n",
      "Epoch 33/100\n",
      "181/181 [==============================] - 91s 503ms/step - loss: 0.2185 - accuracy: 0.9430 - val_loss: 0.9050 - val_accuracy: 0.8068\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.87825\n",
      "Epoch 34/100\n",
      "181/181 [==============================] - 88s 487ms/step - loss: 0.2725 - accuracy: 0.9325 - val_loss: 0.2828 - val_accuracy: 0.9253\n",
      "\n",
      "Epoch 00034: val_accuracy improved from 0.87825 to 0.92532, saving model to efficientB3_1.h5\n",
      "Epoch 35/100\n",
      "181/181 [==============================] - 88s 484ms/step - loss: 0.2079 - accuracy: 0.9451 - val_loss: 0.7545 - val_accuracy: 0.8068\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.92532\n",
      "Epoch 36/100\n",
      "181/181 [==============================] - 88s 486ms/step - loss: 0.2601 - accuracy: 0.9433 - val_loss: 0.8247 - val_accuracy: 0.8068\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.92532\n",
      "Epoch 37/100\n",
      "181/181 [==============================] - 88s 486ms/step - loss: 0.2117 - accuracy: 0.9524 - val_loss: 0.4278 - val_accuracy: 0.8815\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.92532\n",
      "Epoch 38/100\n",
      "181/181 [==============================] - 89s 494ms/step - loss: 0.2541 - accuracy: 0.9314 - val_loss: 0.7586 - val_accuracy: 0.8084\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.92532\n",
      "Epoch 39/100\n",
      "181/181 [==============================] - 88s 489ms/step - loss: 0.2373 - accuracy: 0.9369 - val_loss: 0.3217 - val_accuracy: 0.9172\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.92532\n",
      "Epoch 40/100\n",
      "181/181 [==============================] - 90s 495ms/step - loss: 0.2185 - accuracy: 0.9399 - val_loss: 0.7914 - val_accuracy: 0.8068\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.92532\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181/181 [==============================] - 91s 504ms/step - loss: 0.2572 - accuracy: 0.9453 - val_loss: 0.8034 - val_accuracy: 0.8019\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.92532\n",
      "Epoch 42/100\n",
      "181/181 [==============================] - 89s 491ms/step - loss: 0.2334 - accuracy: 0.9478 - val_loss: 0.5995 - val_accuracy: 0.8474\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.92532\n",
      "Epoch 43/100\n",
      "181/181 [==============================] - 88s 484ms/step - loss: 0.1540 - accuracy: 0.9562 - val_loss: 0.4712 - val_accuracy: 0.8523\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.92532\n",
      "Epoch 44/100\n",
      "181/181 [==============================] - 87s 478ms/step - loss: 0.2076 - accuracy: 0.9516 - val_loss: 0.7560 - val_accuracy: 0.8068\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.92532\n",
      "Epoch 45/100\n",
      "181/181 [==============================] - 86s 476ms/step - loss: 0.1812 - accuracy: 0.9516 - val_loss: 0.6038 - val_accuracy: 0.8198\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.92532\n",
      "Epoch 46/100\n",
      "181/181 [==============================] - 87s 480ms/step - loss: 0.2261 - accuracy: 0.9399 - val_loss: 1.7187 - val_accuracy: 0.5195\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.92532\n",
      "Epoch 47/100\n",
      "181/181 [==============================] - 86s 474ms/step - loss: 0.1871 - accuracy: 0.9497 - val_loss: 0.8381 - val_accuracy: 0.6867\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.92532\n",
      "Epoch 48/100\n",
      "181/181 [==============================] - 86s 473ms/step - loss: 0.1986 - accuracy: 0.9525 - val_loss: 0.7204 - val_accuracy: 0.8036\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.92532\n",
      "Epoch 49/100\n",
      "181/181 [==============================] - 86s 476ms/step - loss: 0.2551 - accuracy: 0.9407 - val_loss: 0.7605 - val_accuracy: 0.6412\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.92532\n",
      "Epoch 50/100\n",
      "181/181 [==============================] - 90s 497ms/step - loss: 0.1658 - accuracy: 0.9554 - val_loss: 0.6312 - val_accuracy: 0.8068\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.92532\n",
      "Epoch 51/100\n",
      "181/181 [==============================] - 88s 485ms/step - loss: 0.2140 - accuracy: 0.9430 - val_loss: 0.7945 - val_accuracy: 0.7403\n",
      "\n",
      "Epoch 00051: val_accuracy did not improve from 0.92532\n",
      "Epoch 52/100\n",
      "181/181 [==============================] - 87s 480ms/step - loss: 0.2449 - accuracy: 0.9368 - val_loss: 0.4797 - val_accuracy: 0.8685\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.92532\n",
      "Epoch 53/100\n",
      "181/181 [==============================] - 87s 483ms/step - loss: 0.2075 - accuracy: 0.9454 - val_loss: 0.3467 - val_accuracy: 0.9026\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.92532\n",
      "Epoch 54/100\n",
      "181/181 [==============================] - 89s 488ms/step - loss: 0.2219 - accuracy: 0.9449 - val_loss: 0.5394 - val_accuracy: 0.8068\n",
      "\n",
      "Epoch 00054: val_accuracy did not improve from 0.92532\n",
      "Epoch 55/100\n",
      "181/181 [==============================] - 87s 480ms/step - loss: 0.2413 - accuracy: 0.9393 - val_loss: 0.9342 - val_accuracy: 0.8068\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.92532\n",
      "Epoch 56/100\n",
      "181/181 [==============================] - 90s 496ms/step - loss: 0.2515 - accuracy: 0.9308 - val_loss: 1.2737 - val_accuracy: 0.8068\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.92532\n",
      "Epoch 57/100\n",
      "181/181 [==============================] - 90s 498ms/step - loss: 0.2309 - accuracy: 0.9350 - val_loss: 0.4137 - val_accuracy: 0.8815\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.92532\n",
      "Epoch 58/100\n",
      "181/181 [==============================] - 87s 481ms/step - loss: 0.2529 - accuracy: 0.9467 - val_loss: 0.3516 - val_accuracy: 0.9091\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.92532\n",
      "Epoch 59/100\n",
      "181/181 [==============================] - 84s 465ms/step - loss: 0.1977 - accuracy: 0.9474 - val_loss: 0.9817 - val_accuracy: 0.8068\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 0.92532\n",
      "Epoch 60/100\n",
      "181/181 [==============================] - 84s 466ms/step - loss: 0.1986 - accuracy: 0.9492 - val_loss: 0.4861 - val_accuracy: 0.8604\n",
      "\n",
      "Epoch 00060: val_accuracy did not improve from 0.92532\n",
      "Epoch 61/100\n",
      "181/181 [==============================] - 84s 464ms/step - loss: 0.1897 - accuracy: 0.9503 - val_loss: 0.5213 - val_accuracy: 0.8263\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.92532\n",
      "Epoch 62/100\n",
      "181/181 [==============================] - 89s 494ms/step - loss: 0.1894 - accuracy: 0.9442 - val_loss: 0.4143 - val_accuracy: 0.8588\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.92532\n",
      "Epoch 63/100\n",
      "181/181 [==============================] - 88s 486ms/step - loss: 0.2068 - accuracy: 0.9476 - val_loss: 1.1707 - val_accuracy: 0.5942\n",
      "\n",
      "Epoch 00063: val_accuracy did not improve from 0.92532\n",
      "Epoch 64/100\n",
      "181/181 [==============================] - 88s 484ms/step - loss: 0.2051 - accuracy: 0.9500 - val_loss: 0.3549 - val_accuracy: 0.9221\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.92532\n",
      "Epoch 65/100\n",
      "181/181 [==============================] - 90s 494ms/step - loss: 0.1896 - accuracy: 0.9433 - val_loss: 0.6638 - val_accuracy: 0.8101\n",
      "\n",
      "Epoch 00065: val_accuracy did not improve from 0.92532\n",
      "Epoch 66/100\n",
      "181/181 [==============================] - 90s 497ms/step - loss: 0.1556 - accuracy: 0.9587 - val_loss: 0.5701 - val_accuracy: 0.7955\n",
      "\n",
      "Epoch 00066: val_accuracy did not improve from 0.92532\n",
      "Epoch 67/100\n",
      "181/181 [==============================] - 88s 486ms/step - loss: 0.1922 - accuracy: 0.9436 - val_loss: 0.3986 - val_accuracy: 0.8831\n",
      "\n",
      "Epoch 00067: val_accuracy did not improve from 0.92532\n",
      "Epoch 68/100\n",
      "181/181 [==============================] - 86s 476ms/step - loss: 0.2157 - accuracy: 0.9438 - val_loss: 0.5581 - val_accuracy: 0.8523\n",
      "\n",
      "Epoch 00068: val_accuracy did not improve from 0.92532\n",
      "Epoch 69/100\n",
      "181/181 [==============================] - 87s 481ms/step - loss: 0.2558 - accuracy: 0.9400 - val_loss: 0.9871 - val_accuracy: 0.6997\n",
      "\n",
      "Epoch 00069: val_accuracy did not improve from 0.92532\n",
      "Epoch 70/100\n",
      "181/181 [==============================] - 87s 482ms/step - loss: 0.2377 - accuracy: 0.9438 - val_loss: 0.8640 - val_accuracy: 0.5763\n",
      "\n",
      "Epoch 00070: val_accuracy did not improve from 0.92532\n",
      "Epoch 71/100\n",
      "181/181 [==============================] - 87s 481ms/step - loss: 0.1682 - accuracy: 0.9433 - val_loss: 0.3527 - val_accuracy: 0.9075\n",
      "\n",
      "Epoch 00071: val_accuracy did not improve from 0.92532\n",
      "Epoch 72/100\n",
      "181/181 [==============================] - 87s 478ms/step - loss: 0.2548 - accuracy: 0.9287 - val_loss: 0.7909 - val_accuracy: 0.8117\n",
      "\n",
      "Epoch 00072: val_accuracy did not improve from 0.92532\n",
      "Epoch 73/100\n",
      "181/181 [==============================] - 89s 492ms/step - loss: 0.2125 - accuracy: 0.9503 - val_loss: 1.2035 - val_accuracy: 0.8068\n",
      "\n",
      "Epoch 00073: val_accuracy did not improve from 0.92532\n",
      "Epoch 74/100\n",
      "181/181 [==============================] - 87s 479ms/step - loss: 0.1657 - accuracy: 0.9576 - val_loss: 0.7909 - val_accuracy: 0.8084\n",
      "\n",
      "Epoch 00074: val_accuracy did not improve from 0.92532\n",
      "Epoch 75/100\n",
      "181/181 [==============================] - 87s 477ms/step - loss: 0.2108 - accuracy: 0.9363 - val_loss: 0.8110 - val_accuracy: 0.8084\n",
      "\n",
      "Epoch 00075: val_accuracy did not improve from 0.92532\n",
      "Epoch 76/100\n",
      "181/181 [==============================] - 85s 472ms/step - loss: 0.2277 - accuracy: 0.9416 - val_loss: 0.9597 - val_accuracy: 0.8068\n",
      "\n",
      "Epoch 00076: val_accuracy did not improve from 0.92532\n",
      "Epoch 77/100\n",
      "181/181 [==============================] - 89s 488ms/step - loss: 0.1664 - accuracy: 0.9615 - val_loss: 0.8090 - val_accuracy: 0.8068\n",
      "\n",
      "Epoch 00077: val_accuracy did not improve from 0.92532\n",
      "Epoch 78/100\n",
      "181/181 [==============================] - 85s 467ms/step - loss: 0.1782 - accuracy: 0.9564 - val_loss: 0.2743 - val_accuracy: 0.9253\n",
      "\n",
      "Epoch 00078: val_accuracy did not improve from 0.92532\n",
      "Epoch 79/100\n",
      "181/181 [==============================] - 86s 474ms/step - loss: 0.1914 - accuracy: 0.9486 - val_loss: 0.7637 - val_accuracy: 0.8052\n",
      "\n",
      "Epoch 00079: val_accuracy did not improve from 0.92532\n",
      "Epoch 80/100\n",
      "181/181 [==============================] - 88s 487ms/step - loss: 0.2536 - accuracy: 0.9370 - val_loss: 3.5710 - val_accuracy: 0.1867\n",
      "\n",
      "Epoch 00080: val_accuracy did not improve from 0.92532\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181/181 [==============================] - 85s 467ms/step - loss: 0.1703 - accuracy: 0.9553 - val_loss: 1.0103 - val_accuracy: 0.8068\n",
      "\n",
      "Epoch 00081: val_accuracy did not improve from 0.92532\n",
      "Epoch 82/100\n",
      "181/181 [==============================] - 86s 472ms/step - loss: 0.2334 - accuracy: 0.9411 - val_loss: 0.2952 - val_accuracy: 0.9042\n",
      "\n",
      "Epoch 00082: val_accuracy did not improve from 0.92532\n",
      "Epoch 83/100\n",
      "181/181 [==============================] - 83s 461ms/step - loss: 0.1373 - accuracy: 0.9653 - val_loss: 0.9225 - val_accuracy: 0.7224\n",
      "\n",
      "Epoch 00083: val_accuracy did not improve from 0.92532\n",
      "Epoch 84/100\n",
      "181/181 [==============================] - 85s 469ms/step - loss: 0.2039 - accuracy: 0.9467 - val_loss: 0.7284 - val_accuracy: 0.8068\n",
      "\n",
      "Epoch 00084: val_accuracy did not improve from 0.92532\n",
      "Epoch 00084: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2c40261f10>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 100\n",
    "nb_train_steps = train.shape[0] // batch_size\n",
    "nb_val_steps = test.shape[0] // batch_size\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"efficientB3_1.h5\", monitor='val_accuracy', verbose=5, save_best_only=True, save_weights_only=False, mode='auto')\n",
    "\n",
    "early = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=50, verbose=1, mode='auto')\n",
    "\n",
    "model.fit_generator(train_generator, steps_per_epoch=nb_train_steps, epochs=epochs,\n",
    "                              validation_data=test_generator, validation_steps=nb_val_steps, \n",
    "                              verbose=1, callbacks=[checkpoint,early])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
