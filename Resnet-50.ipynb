{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0e40f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-10 16:11:55.523578: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers.merge import concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, BatchNormalization, Dense, Conv2D, MaxPool2D , Flatten, Dropout, GlobalAveragePooling2D, AveragePooling2D, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.applications import ResNet152, ResNet50\n",
    "from tensorflow.keras.applications.densenet import preprocess_input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e9b8e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from PIL import Image\n",
    "sys.modules['Image'] = Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "859d8e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-10 16:11:57.709622: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-01-10 16:11:57.710569: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-01-10 16:11:57.818135: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-10 16:11:57.818500: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.91GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-01-10 16:11:57.818525: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-01-10 16:11:57.830869: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2022-01-10 16:11:57.830971: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-01-10 16:11:57.841573: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-01-10 16:11:57.846434: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-01-10 16:11:57.861567: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-01-10 16:11:57.865693: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2022-01-10 16:11:57.866615: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-01-10 16:11:57.866767: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-10 16:11:57.867204: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-10 16:11:57.868438: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87212145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"GPUs: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b16ba15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_metadata.csv')\n",
    "test = pd.read_csv('test_metadata.csv')\n",
    "#submission = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "train_dir = 'train/'\n",
    "test_dir = 'test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55785abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = []\n",
    "train_data = []\n",
    "for i in range(train.shape[0]):\n",
    "    train_data.append(train_dir + train['image_name'].iloc[i] + '.jpg')\n",
    "    label.append(train['diagnosis'].iloc[i])\n",
    "    \n",
    "test_data = []\n",
    "for i in range(test.shape[0]):\n",
    "    test_data.append(test_dir + test['image'].iloc[i] + '.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4dbde34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiIndex([('atypical melanocytic proliferation',),\n",
      "            (               'cafe-au-lait macule',),\n",
      "            (                       'lentigo NOS',),\n",
      "            (               'lichenoid keratosis',),\n",
      "            (                          'melanoma',),\n",
      "            (                             'nevus',),\n",
      "            (              'seborrheic keratosis',),\n",
      "            (                     'solar lentigo',),\n",
      "            (                           'unknown',)],\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "label_df = pd.DataFrame(label, columns = ['diagnosis'])\n",
    "one_hot_encoder.fit(label_df)\n",
    "\n",
    "label_df_encoded = one_hot_encoder.transform(label_df)\n",
    "label_df_encoded = pd.DataFrame(data=label_df_encoded, columns=one_hot_encoder.categories_)\n",
    "print(label_df_encoded.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23913b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([                               'images',\n",
      "       ('atypical melanocytic proliferation',),\n",
      "                      ('cafe-au-lait macule',),\n",
      "                              ('lentigo NOS',),\n",
      "                      ('lichenoid keratosis',),\n",
      "                                 ('melanoma',),\n",
      "                                    ('nevus',),\n",
      "                     ('seborrheic keratosis',),\n",
      "                            ('solar lentigo',),\n",
      "                                  ('unknown',)],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.DataFrame(train_data)\n",
    "df_train.columns = ['images']\n",
    "df_train = pd.concat([df_train, label_df_encoded], axis = 1)\n",
    "print(df_train.columns)\n",
    "df_test = pd.DataFrame(test_data)\n",
    "df_test.columns = ['images']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0badc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_train.iloc[:, 0], df_train.iloc[:,1::], test_size = 0.3, random_state = 42)\n",
    "\n",
    "train = pd.DataFrame(X_train)\n",
    "train.columns = ['images']\n",
    "train = pd.concat([train, y_train], axis = 1)\n",
    "\n",
    "test = pd.DataFrame(X_test)\n",
    "test.columns = ['images']\n",
    "test = pd.concat([test, y_test], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a37d5538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23188 validated image filenames.\n",
      "Found 9938 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,rotation_range=50,\n",
    "                                   zoom_range = 0.3,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range = 0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode = 'nearest')\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train,\n",
    "    x_col=train.columns[0],\n",
    "    y_col=train.columns[1:],\n",
    "    target_size=(224, 224),\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    class_mode='raw')\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    test,\n",
    "    x_col=test.columns[0],\n",
    "    y_col=test.columns[1:],\n",
    "    target_size=(224, 224),\n",
    "    shuffle=False,\n",
    "    batch_size=8,\n",
    "    class_mode='raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01f2510f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-10 16:11:58.465236: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-10 16:11:58.465502: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-01-10 16:11:58.465626: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-10 16:11:58.465959: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.91GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-01-10 16:11:58.465982: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-01-10 16:11:58.466009: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2022-01-10 16:11:58.466020: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-01-10 16:11:58.466030: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-01-10 16:11:58.466039: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-01-10 16:11:58.466049: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-01-10 16:11:58.466059: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2022-01-10 16:11:58.466069: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-01-10 16:11:58.466117: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-10 16:11:58.466450: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-10 16:11:58.466824: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-01-10 16:11:58.467844: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-01-10 16:11:59.718972: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-01-10 16:11:59.718995: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2022-01-10 16:11:59.719003: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2022-01-10 16:11:59.721158: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-10 16:11:59.721857: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-10 16:11:59.722434: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-10 16:11:59.722946: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10087 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)\n"
     ]
    }
   ],
   "source": [
    "baseModel = ResNet50(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n",
    "headModel = baseModel.output\n",
    "headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(256, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "class_num = 9\n",
    "headModel = Dense(class_num, activation=\"softmax\")(headModel)\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a23fddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 1, 1, 2048)   0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2048)         0           average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          524544      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 256)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 9)            2313        dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 24,114,569\n",
      "Trainable params: 24,061,449\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "opt = Adam(lr=0.0001)\n",
    "\n",
    "model.compile(optimizer= opt,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2b73604",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deeplab/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      "2022-01-10 16:12:01.324051: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-01-10 16:12:01.346118: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 4200000000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-10 16:12:04.369690: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2022-01-10 16:12:04.902423: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-01-10 16:12:04.922243: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181/181 [==============================] - 99s 510ms/step - loss: 0.7303 - accuracy: 0.8198 - val_loss: 0.9987 - val_accuracy: 0.8068\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.80682, saving model to resnet-50.h5\n",
      "Epoch 2/100\n",
      "181/181 [==============================] - 87s 483ms/step - loss: 0.3575 - accuracy: 0.9041 - val_loss: 1.7072 - val_accuracy: 0.8068\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.80682\n",
      "Epoch 3/100\n",
      "181/181 [==============================] - 87s 480ms/step - loss: 0.3970 - accuracy: 0.9047 - val_loss: 1.9360 - val_accuracy: 0.8133\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.80682 to 0.81331, saving model to resnet-50.h5\n",
      "Epoch 4/100\n",
      "181/181 [==============================] - 86s 477ms/step - loss: 0.3511 - accuracy: 0.9138 - val_loss: 0.8207 - val_accuracy: 0.6932\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.81331\n",
      "Epoch 5/100\n",
      "181/181 [==============================] - 85s 467ms/step - loss: 0.2923 - accuracy: 0.9263 - val_loss: 0.4299 - val_accuracy: 0.8831\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.81331 to 0.88312, saving model to resnet-50.h5\n",
      "Epoch 6/100\n",
      "181/181 [==============================] - 84s 465ms/step - loss: 0.2974 - accuracy: 0.9247 - val_loss: 0.3203 - val_accuracy: 0.9172\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.88312 to 0.91721, saving model to resnet-50.h5\n",
      "Epoch 7/100\n",
      "181/181 [==============================] - 84s 465ms/step - loss: 0.3075 - accuracy: 0.9219 - val_loss: 0.3429 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.91721 to 0.92857, saving model to resnet-50.h5\n",
      "Epoch 8/100\n",
      "181/181 [==============================] - 81s 450ms/step - loss: 0.2626 - accuracy: 0.9342 - val_loss: 0.3832 - val_accuracy: 0.9253\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.92857\n",
      "Epoch 9/100\n",
      "181/181 [==============================] - 83s 460ms/step - loss: 0.3019 - accuracy: 0.9338 - val_loss: 0.3037 - val_accuracy: 0.9221\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.92857\n",
      "Epoch 10/100\n",
      "181/181 [==============================] - 82s 454ms/step - loss: 0.2591 - accuracy: 0.9347 - val_loss: 0.3985 - val_accuracy: 0.8994\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.92857\n",
      "Epoch 11/100\n",
      "181/181 [==============================] - 83s 460ms/step - loss: 0.2931 - accuracy: 0.9272 - val_loss: 0.3401 - val_accuracy: 0.9269\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.92857\n",
      "Epoch 12/100\n",
      "181/181 [==============================] - 85s 468ms/step - loss: 0.2318 - accuracy: 0.9528 - val_loss: 0.3200 - val_accuracy: 0.9253\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.92857\n",
      "Epoch 13/100\n",
      "181/181 [==============================] - 84s 466ms/step - loss: 0.2473 - accuracy: 0.9422 - val_loss: 0.2991 - val_accuracy: 0.9302\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.92857 to 0.93019, saving model to resnet-50.h5\n",
      "Epoch 14/100\n",
      "181/181 [==============================] - 83s 461ms/step - loss: 0.3262 - accuracy: 0.9154 - val_loss: 0.2755 - val_accuracy: 0.9205\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.93019\n",
      "Epoch 15/100\n",
      "181/181 [==============================] - 83s 456ms/step - loss: 0.2678 - accuracy: 0.9278 - val_loss: 0.3158 - val_accuracy: 0.9140\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.93019\n",
      "Epoch 16/100\n",
      "181/181 [==============================] - 84s 463ms/step - loss: 0.2775 - accuracy: 0.9334 - val_loss: 0.3159 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.93019\n",
      "Epoch 17/100\n",
      "181/181 [==============================] - 82s 452ms/step - loss: 0.2508 - accuracy: 0.9380 - val_loss: 0.3119 - val_accuracy: 0.9253\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.93019\n",
      "Epoch 18/100\n",
      "181/181 [==============================] - 81s 448ms/step - loss: 0.2797 - accuracy: 0.9199 - val_loss: 0.4365 - val_accuracy: 0.8831\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.93019\n",
      "Epoch 19/100\n",
      "181/181 [==============================] - 80s 442ms/step - loss: 0.2102 - accuracy: 0.9467 - val_loss: 0.3312 - val_accuracy: 0.9042\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.93019\n",
      "Epoch 20/100\n",
      "181/181 [==============================] - 82s 450ms/step - loss: 0.3570 - accuracy: 0.9060 - val_loss: 0.3201 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.93019\n",
      "Epoch 21/100\n",
      "181/181 [==============================] - 81s 445ms/step - loss: 0.2493 - accuracy: 0.9432 - val_loss: 0.3295 - val_accuracy: 0.9188\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.93019\n",
      "Epoch 22/100\n",
      "181/181 [==============================] - 82s 452ms/step - loss: 0.2585 - accuracy: 0.9427 - val_loss: 0.3067 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.93019\n",
      "Epoch 23/100\n",
      "181/181 [==============================] - 81s 449ms/step - loss: 0.3362 - accuracy: 0.9261 - val_loss: 0.4092 - val_accuracy: 0.9156\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.93019\n",
      "Epoch 24/100\n",
      "181/181 [==============================] - 83s 459ms/step - loss: 0.2520 - accuracy: 0.9354 - val_loss: 0.3659 - val_accuracy: 0.9188\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.93019\n",
      "Epoch 25/100\n",
      "181/181 [==============================] - 81s 447ms/step - loss: 0.2994 - accuracy: 0.9307 - val_loss: 0.3132 - val_accuracy: 0.9205\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.93019\n",
      "Epoch 26/100\n",
      "181/181 [==============================] - 81s 448ms/step - loss: 0.2128 - accuracy: 0.9469 - val_loss: 0.3611 - val_accuracy: 0.9237\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.93019\n",
      "Epoch 27/100\n",
      "181/181 [==============================] - 78s 432ms/step - loss: 0.2444 - accuracy: 0.9444 - val_loss: 0.3515 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.93019\n",
      "Epoch 28/100\n",
      "181/181 [==============================] - 80s 441ms/step - loss: 0.2116 - accuracy: 0.9386 - val_loss: 0.3659 - val_accuracy: 0.9188\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.93019\n",
      "Epoch 29/100\n",
      "181/181 [==============================] - 79s 437ms/step - loss: 0.1758 - accuracy: 0.9505 - val_loss: 0.3227 - val_accuracy: 0.9269\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.93019\n",
      "Epoch 30/100\n",
      "181/181 [==============================] - 80s 443ms/step - loss: 0.2398 - accuracy: 0.9487 - val_loss: 0.2840 - val_accuracy: 0.9318\n",
      "\n",
      "Epoch 00030: val_accuracy improved from 0.93019 to 0.93182, saving model to resnet-50.h5\n",
      "Epoch 31/100\n",
      "181/181 [==============================] - 80s 441ms/step - loss: 0.2309 - accuracy: 0.9419 - val_loss: 0.2855 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.93182\n",
      "Epoch 32/100\n",
      "181/181 [==============================] - 82s 453ms/step - loss: 0.2398 - accuracy: 0.9405 - val_loss: 0.3776 - val_accuracy: 0.9140\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.93182\n",
      "Epoch 33/100\n",
      "181/181 [==============================] - 82s 452ms/step - loss: 0.2276 - accuracy: 0.9441 - val_loss: 0.2851 - val_accuracy: 0.9302\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.93182\n",
      "Epoch 34/100\n",
      "181/181 [==============================] - 81s 448ms/step - loss: 0.2948 - accuracy: 0.9285 - val_loss: 0.3219 - val_accuracy: 0.9302\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.93182\n",
      "Epoch 35/100\n",
      "181/181 [==============================] - 80s 440ms/step - loss: 0.2378 - accuracy: 0.9473 - val_loss: 0.3169 - val_accuracy: 0.9334\n",
      "\n",
      "Epoch 00035: val_accuracy improved from 0.93182 to 0.93344, saving model to resnet-50.h5\n",
      "Epoch 36/100\n",
      "181/181 [==============================] - 78s 433ms/step - loss: 0.1882 - accuracy: 0.9599 - val_loss: 0.2732 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.93344\n",
      "Epoch 37/100\n",
      "181/181 [==============================] - 80s 443ms/step - loss: 0.3029 - accuracy: 0.9257 - val_loss: 0.8613 - val_accuracy: 0.6769\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.93344\n",
      "Epoch 38/100\n",
      "181/181 [==============================] - 79s 435ms/step - loss: 0.2632 - accuracy: 0.9310 - val_loss: 0.3540 - val_accuracy: 0.9205\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.93344\n",
      "Epoch 39/100\n",
      "181/181 [==============================] - 79s 439ms/step - loss: 0.2209 - accuracy: 0.9513 - val_loss: 0.2786 - val_accuracy: 0.9334\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.93344\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181/181 [==============================] - 79s 436ms/step - loss: 0.1601 - accuracy: 0.9611 - val_loss: 0.2990 - val_accuracy: 0.9302\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.93344\n",
      "Epoch 41/100\n",
      "181/181 [==============================] - 79s 437ms/step - loss: 0.3055 - accuracy: 0.9205 - val_loss: 0.3067 - val_accuracy: 0.9221\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.93344\n",
      "Epoch 42/100\n",
      "181/181 [==============================] - 81s 446ms/step - loss: 0.2269 - accuracy: 0.9447 - val_loss: 0.3174 - val_accuracy: 0.9302\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.93344\n",
      "Epoch 43/100\n",
      "181/181 [==============================] - 81s 449ms/step - loss: 0.2316 - accuracy: 0.9413 - val_loss: 0.3229 - val_accuracy: 0.9334\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.93344\n",
      "Epoch 44/100\n",
      "181/181 [==============================] - 81s 446ms/step - loss: 0.2000 - accuracy: 0.9493 - val_loss: 0.3057 - val_accuracy: 0.9188\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.93344\n",
      "Epoch 45/100\n",
      "181/181 [==============================] - 82s 454ms/step - loss: 0.2303 - accuracy: 0.9428 - val_loss: 0.3677 - val_accuracy: 0.9221\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.93344\n",
      "Epoch 46/100\n",
      "181/181 [==============================] - 81s 447ms/step - loss: 0.2007 - accuracy: 0.9527 - val_loss: 0.2950 - val_accuracy: 0.9334\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.93344\n",
      "Epoch 47/100\n",
      "181/181 [==============================] - 83s 456ms/step - loss: 0.1873 - accuracy: 0.9590 - val_loss: 0.3023 - val_accuracy: 0.9334\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.93344\n",
      "Epoch 48/100\n",
      "181/181 [==============================] - 78s 434ms/step - loss: 0.2009 - accuracy: 0.9418 - val_loss: 0.3373 - val_accuracy: 0.9140\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.93344\n",
      "Epoch 49/100\n",
      "181/181 [==============================] - 80s 444ms/step - loss: 0.2187 - accuracy: 0.9460 - val_loss: 0.3139 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.93344\n",
      "Epoch 50/100\n",
      "181/181 [==============================] - 81s 446ms/step - loss: 0.2911 - accuracy: 0.9404 - val_loss: 0.2544 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.93344\n",
      "Epoch 51/100\n",
      "181/181 [==============================] - 80s 441ms/step - loss: 0.2142 - accuracy: 0.9395 - val_loss: 0.3404 - val_accuracy: 0.9140\n",
      "\n",
      "Epoch 00051: val_accuracy did not improve from 0.93344\n",
      "Epoch 52/100\n",
      "181/181 [==============================] - 81s 448ms/step - loss: 0.2524 - accuracy: 0.9420 - val_loss: 0.4653 - val_accuracy: 0.9269\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.93344\n",
      "Epoch 53/100\n",
      "181/181 [==============================] - 81s 445ms/step - loss: 0.2937 - accuracy: 0.9369 - val_loss: 0.3523 - val_accuracy: 0.9318\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.93344\n",
      "Epoch 54/100\n",
      "181/181 [==============================] - 80s 441ms/step - loss: 0.2529 - accuracy: 0.9463 - val_loss: 0.3079 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00054: val_accuracy did not improve from 0.93344\n",
      "Epoch 55/100\n",
      "181/181 [==============================] - 81s 445ms/step - loss: 0.2419 - accuracy: 0.9402 - val_loss: 0.3206 - val_accuracy: 0.9269\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.93344\n",
      "Epoch 00055: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f76dda6ad60>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 100\n",
    "nb_train_steps = train.shape[0] // batch_size\n",
    "nb_val_steps = test.shape[0] // batch_size\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"resnet-50.h5\", monitor='val_accuracy', verbose=5, save_best_only=True, save_weights_only=False, mode='auto')\n",
    "\n",
    "early = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=20, verbose=1, mode='auto')\n",
    "\n",
    "model.fit_generator(train_generator, steps_per_epoch=nb_train_steps, epochs=epochs,\n",
    "                              validation_data=test_generator, validation_steps=nb_val_steps, \n",
    "                              verbose=1, callbacks=[checkpoint,early])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
